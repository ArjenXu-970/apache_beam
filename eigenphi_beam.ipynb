{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e3e9466-c59e-469a-8c5f-ff9f1c455e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0874eaa0-c6db-440a-9712-b3659851d075",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 使用pandas 生产数据，date_time 为时间戳，time_int是该时间所对应的int值，为了方便之后分组处理，然后是温度，范围为0-100 随机分布，写进csv文件\n",
    "\n",
    "df=pd.DataFrame()\n",
    "date_time=[]\n",
    "temp=[]\n",
    "time_int=[]\n",
    "for i in range(3600):   ### 假设从 时间戳=0 那一秒开始，每秒产生一个数据产生 3600秒 \n",
    "    date = datetime.datetime.fromtimestamp(i)\n",
    "    date_time_str = date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    tem=round(random.uniform(0.0,100.0),2)  ### 随机分布 保留两位小数\n",
    "    \n",
    "    date_time.append(date)\n",
    "    temp.append(tem)\n",
    "    time_int.append(int(time.mktime(date.timetuple())))   ####将读取到的时间戳文件转换成int 方便之后分组\n",
    "df[\"date_time\"]=date_time\n",
    "df[\"temperature\"]=temp\n",
    "df[\"time_int\"]=time_int\n",
    "df.to_csv(\"temperature.csv\",index=False)\n",
    "\n",
    "\n",
    "###我们也可以用一些方法来生产实时数据，然后用beam stream来随时读取，这个也是之后可以改进的点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3b6d2497-c599-4086-af50-1a6b7e878fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 整合数据函数  使用模板\n",
    "\n",
    "class MinMaxMeanFn(beam.CombineFn):  \n",
    "\n",
    "    def create_accumulator(self):\n",
    "        # sum, min, max, count\n",
    "        return (0.0, 999999999.0, 0.0, 0)\n",
    "\n",
    "    def add_input(self, cur_data, input):  ##按照时间分组好的数据作为input\n",
    "        (cur_sum, cur_min, cur_max, count) = cur_data\n",
    "        cur_count = len(input)\n",
    "        \n",
    "        \n",
    "        sum_input=cur_sum\n",
    "        min_input=cur_min\n",
    "        max_input=cur_max\n",
    "        for record in input:     ### 计算每组数据的min，max，avg\n",
    "            sum_input+=float(record[1])\n",
    "            min_input = min(min_input,float(record[1]))\n",
    "            max_input = max(max_input,float(record[1]))\n",
    "        return sum_input , min_input, max_input, cur_count\n",
    "    \n",
    "    def merge_accumulators(self, accumulators):\n",
    "        sums, mins, maxs, counts = zip(*accumulators)\n",
    "        return sum(sums), min(mins), max(maxs), sum(counts)\n",
    "\n",
    "    def extract_output(self, cur_data):\n",
    "        (sum, min, max, count) = cur_data\n",
    "        avg = sum / count if count else float('NaN')\n",
    "        return  {\n",
    "            \"max\": max,\n",
    "            \"min\": min,\n",
    "            \"avg\": \"%.2f\"%avg,\n",
    "            \"count\": count\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f558e92e-1f93-4ff6-a0ef-9d6a54fdf5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x160035da310>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###生产 每一分钟的结果\n",
    "\n",
    "#from external resources\n",
    "\n",
    "start_time=0\n",
    "end_time=3600\n",
    "\n",
    "\n",
    "pipe1 = beam.Pipeline()\n",
    "\n",
    "temperature_per_1min = (pipe1\n",
    "           | \"Read from Text\" >> beam.io.ReadFromText(\"temperature.csv\", skip_header_lines=1) ## 读文件，跳过文件头\n",
    "           | \"split the record\" >> beam.Map(lambda record: record.split(','))   ### 把文件分成每一个record\n",
    "           | 'Filter regular' >> beam.GroupBy(lambda x:int((int(x[2]))/60))  ##### 按照时间将记录分组，除60取结果，数组结果相同说明再同一分钟\n",
    "           |'get min max and mean' >> beam.CombinePerKey(MinMaxMeanFn())  #### 用函数处理分组的结果\n",
    "           |'Format the output' >> beam.Map(lambda x: '{},{},{},{}'.format(x[0],x[1][\"max\"],x[1][\"min\"],x[1][\"avg\"]))  ### 格式化上一步生成的tuple，然后写进文件\n",
    "           | 'Write to text'>> beam.io.WriteToText(\"every_1min_info\",append_trailing_newlines=True,file_name_suffix=\".csv\",header=\"time_range,max_temperature,min_temperature,avg_temperature\")\n",
    ")  \n",
    "                            \n",
    "pipe1.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1bd30f6c-bd66-4f52-b97d-26decbc7c007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x1607df59490>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###生产 每五分钟的结果   道理同上\n",
    "\n",
    "pipe2 = beam.Pipeline()\n",
    "\n",
    "temperature_per_1min = (pipe2\n",
    "           | \"Read from Text\" >> beam.io.ReadFromText(\"temperature.csv\", skip_header_lines=1)\n",
    "           | \"split the record\" >> beam.Map(lambda record: record.split(','))\n",
    "           | 'Filter regular' >> beam.GroupBy(lambda x:int((int(x[2]))/300))\n",
    "           |'get min max and mean' >> beam.CombinePerKey(MinMaxMeanFn())\n",
    "           |'Format the output' >> beam.Map(lambda x: '{},{},{},{}'.format(x[0],x[1][\"max\"],x[1][\"min\"],x[1][\"avg\"]))\n",
    "           | 'Write to text'>> beam.io.WriteToText(\"every_5min_info\",append_trailing_newlines=True,file_name_suffix=\".csv\",header=\"time_range,max_temperature,min_temperature,avg_temperature\")\n",
    ")  \n",
    "                            \n",
    "pipe2.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5029a4d6-4c6f-4942-ae56-e0cf82fdd657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x1607c811dc0>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###生产 每十五分钟的结果   道理同上\n",
    "pipe3 = beam.Pipeline()\n",
    "\n",
    "temperature_per_1min = (pipe3\n",
    "           | \"Read from Text\" >> beam.io.ReadFromText(\"temperature.csv\", skip_header_lines=1)\n",
    "           | \"split the record\" >> beam.Map(lambda record: record.split(','))\n",
    "           | 'Filter regular' >> beam.GroupBy(lambda x:int((int(x[2]))/900))\n",
    "           |'get min max and mean' >> beam.CombinePerKey(MinMaxMeanFn())\n",
    "           |'Format the output' >> beam.Map(lambda x: '{},{},{},{}'.format(x[0],x[1][\"max\"],x[1][\"min\"],x[1][\"avg\"]))\n",
    "           | 'Write to text'>> beam.io.WriteToText(\"every_15min_info\",append_trailing_newlines=True,file_name_suffix=\".csv\",header=\"time_range,max_temperature,min_temperature,avg_temperature\")\n",
    ")  \n",
    "                            \n",
    "pipe3.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cda66c5-cc04-4f0d-a715-c5d15f2d7101",
   "metadata": {},
   "outputs": [],
   "source": [
    "####假设在输入集合中存在一些异常点（超过随机温度范围），如何不使用条件规则（例如直接if判断）来找到这些异常点\n",
    "####因为这个数据是随机分布的，所以最好的办法就是用比较大小的办法来挑出异常点\n",
    "####基于统计学方法，我们还可以用一下几种方法检测异常点\n",
    "####1.数据超过标准差的三倍，可能是异常点\n",
    "####2.我们还可以将数据四分位，然后 小于 q1-1.5*（q3-q1） 和大于 q3+1.5*（q3-q1） 为异常点\n",
    "####3.一些机器学习的方法，比如Random Cut Forest\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
